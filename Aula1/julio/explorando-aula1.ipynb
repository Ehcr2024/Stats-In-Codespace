{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52a5a926",
   "metadata": {},
   "source": [
    "O Polars é uma biblioteca moderna para análise de dados que surgiu em 2020, criada por Ritchie Vink como resposta às limitações de desempenho do Pandas, especialmente em grandes volumes de dados. O conceito central do Polars é oferecer uma engine de consulta analítica extremamente rápida, escrita em Rust e baseada no formato de memória columnar Apache Arrow, permitindo processamento paralelo e otimizações de memória.[1][2][3]\n",
    "\n",
    "### Surgimento e Conceito\n",
    "\n",
    "O Polars nasceu como um projeto pessoal para resolver gargalos de desempenho e uso de memória em bibliotecas tradicionais como o Pandas. Ele foi projetado para ser rápido, eficiente e escalável, especialmente para datasets grandes, utilizando técnicas de processamento paralelo e uma arquitetura close-to-the-metal, ou seja, próxima ao hardware. O Polars pode ser usado tanto de forma “eager” (execução imediata) quanto “lazy” (execução otimizada e diferida), permitindo que o usuário defina pipelines de transformação de dados que são otimizados antes da execução.[2][3][4][1]\n",
    "\n",
    "### Vantagens do Polars\n",
    "\n",
    "- **Desempenho**: O Polars é frequentemente 5 a 10 vezes mais rápido que o Pandas em operações comuns, podendo chegar a 30x em benchmarks específicos.[5][3][6]\n",
    "- **Eficiência de memória**: Utiliza o formato columnar Apache Arrow, reduzindo o uso de memória e permitindo processar datasets maiores do que a RAM disponível, graças ao streaming e ao suporte a dados fora da memória.[3][2]\n",
    "- **Paralelismo**: O Polars aproveita todos os núcleos do processador automaticamente, sem necessidade de configuração adicional.[2][3]\n",
    "- **Sintaxe expressiva**: Oferece uma API intuitiva e encadeável, facilitando a leitura e manutenção do código.[7][4]\n",
    "- **Integração com o ecossistema Python**: Permite fácil integração com outras bibliotecas populares, como Scikit-learn, Matplotlib e frameworks de machine learning.[7][3]\n",
    "- **Open source e ativo**: O Polars é open source, possui uma comunidade crescente e está em constante evolução.[1][2]\n",
    "\n",
    "### Exemplo concreto\n",
    "\n",
    "Imagine que você está analisando dados de tráfego de uma cidade, com milhões de registros de veículos. Com o Pandas, operações como agrupamento, filtragem e agregação podem ser lentas e exigir muita memória. Já com o Polars, essas mesmas operações são executadas rapidamente, permitindo que você explore diferentes cenários e faça ajustes em tempo real, sem precisar esperar minutos ou horas para ver o resultado.[3][2]\n",
    "\n",
    "### Conexão com o que já foi aprendido\n",
    "\n",
    "Se você já usou o Pandas, perceberá que o Polars segue uma lógica semelhante, mas com ganhos de desempenho e eficiência que fazem toda a diferença em projetos reais de engenharia de transporte, onde dados são grandes e decisões precisam ser rápidas.[7][3]\n",
    "\n",
    "### Estimulando a curiosidade\n",
    "\n",
    "E se você pudesse processar um dataset de 10 GB em segundos, sem precisar de um cluster de computadores? O Polars está tornando isso possível. Que outros desafios de análise de dados poderiam ser resolvidos com uma ferramenta tão eficiente?\n",
    "\n",
    "***\n",
    "\n",
    "O Polars é uma excelente opção para quem busca desempenho, eficiência e escalabilidade em análise de dados, especialmente em projetos de engenharia e ciência de dados aplicada.[2][3][7]\n",
    "\n",
    "[1](https://en.wikipedia.org/wiki/Polars_(software))\n",
    "[2](https://pola.rs)\n",
    "[3](https://deepnote.com/blog/ultimate-guide-to-the-polars-library-in-python)\n",
    "[4](https://www.datacamp.com/blog/an-introduction-to-polars-python-s-tool-for-large-scale-data-analysis)\n",
    "[5](https://www.stratascratch.com/blog/polars-vs-pandas/)\n",
    "[6](https://blog.jetbrains.com/pycharm/2024/07/polars-vs-pandas/)\n",
    "[7](https://www.geeksforgeeks.org/data-analysis/mastering-polars-high-efficiency-data-analysis-and-manipulation/)\n",
    "[8](https://dl.acm.org/doi/10.1145/3661167.3661203)\n",
    "[9](https://www.mdpi.com/2073-431X/14/8/319)\n",
    "[10](https://www.sciendo.com/article/10.2478/amns.2023.2.01212)\n",
    "[11](https://proceedings.gpntbsib.ru/jour/article/view/942)\n",
    "[12](https://joss.theoj.org/papers/10.21105/joss.06943)\n",
    "[13](https://www.tandfonline.com/doi/full/10.1080/01616846.2023.2296179)\n",
    "[14](http://dspace.ada.edu.az/xmlui/handle/20.500.12181/1180)\n",
    "[15](http://librinfosciences.knukim.edu.ua/article/view/318289)\n",
    "[16](https://onlinelibrary.wiley.com/doi/10.1111/1750-0206.12725)\n",
    "[17](https://alhayat.or.id/index.php/alhayat/article/view/440)\n",
    "[18](https://arxiv.org/pdf/0805.1165.pdf)\n",
    "[19](https://www.atmos-chem-phys.net/18/13547/2018/acp-18-13547-2018.pdf)\n",
    "[20](http://arxiv.org/pdf/2409.01363.pdf)\n",
    "[21](https://acp.copernicus.org/articles/15/3873/2015/acp-15-3873-2015.pdf)\n",
    "[22](https://arxiv.org/pdf/0805.4389.pdf)\n",
    "[23](https://arxiv.org/abs/0804.3593)\n",
    "[24](https://arxiv.org/pdf/1003.4682.pdf)\n",
    "[25](https://arxiv.org/pdf/1205.6276.pdf)\n",
    "[26](https://data-ai.theodo.com/en/technical-blog/polars-vs-pandas)\n",
    "[27](https://github.com/pola-rs/polars)\n",
    "[28](https://towardsdatascience.com/rust-polars-unlocking-high-performance-data-analysis-part-1-ce42af370ece/)\n",
    "[29](https://www.reddit.com/r/Python/comments/1jg402b/polars_vs_pandas/)\n",
    "[30](https://dskrzypiec.dev/polars/)\n",
    "[31](https://towardsdatascience.com/polars-vs-pandas-an-independent-speed-comparison/)\n",
    "[32](https://pola.rs/about-us/)\n",
    "[33](https://realpython.com/polars-vs-pandas/)\n",
    "[34](https://docs.pola.rs/user-guide/migration/pandas/)\n",
    "[35](https://pypi.org/project/polars/)\n",
    "[36](https://www.factspan.com/blogs/choosing-polars-over-pandas-for-high-performance-data-analysis/)\n",
    "[37](https://labs.quansight.org/blog/dataframe-group-by)\n",
    "[38](https://coditation.com/blog/high-performance-data-analysis-with-polars-a-comprehensive-guide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96299b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumo de Tamanhos em Disco:\n",
      "- .tab:      40.26 MB\n",
      "- .parquet:  4.22 MB\n",
      "- Fator de redução: 9.53x (tab/parquet)\n",
      "\n",
      "Tempos (segundos):\n",
      "- Leitura .tab:          0.2354s\n",
      "- Escrita .parquet:      0.1520s\n",
      "- Leitura .parquet:      0.0470s\n",
      "- Describe .tab:         0.1396s\n",
      "- Describe .parquet:     0.0673s\n",
      "\n",
      "Memória estimada dos DataFrames:\n",
      "- DF (.tab):      43.73 MB\n",
      "- DF (.parquet):  43.73 MB\n",
      "\n",
      "Esquema (dtypes) detectado:\n",
      "Schema({'day': String, 'origin': String, 'destination': String, 'travel_count_no_factor': Int64, 'travel_count_fix_factor': Int64, 'travell_count_adap_factor': Int64})\n",
      "\n",
      "Análise descritiva (.tab):\n",
      "shape: (9, 7)\n",
      "┌────────────┬────────────┬─────────────┬─────────────┬──────────────┬──────────────┬──────────────┐\n",
      "│ statistic  ┆ day        ┆ origin      ┆ destination ┆ travel_count ┆ travel_count ┆ travell_coun │\n",
      "│ ---        ┆ ---        ┆ ---         ┆ ---         ┆ _no_factor   ┆ _fix_factor  ┆ t_adap_facto │\n",
      "│ str        ┆ str        ┆ str         ┆ str         ┆ ---          ┆ ---          ┆ r            │\n",
      "│            ┆            ┆             ┆             ┆ f64          ┆ f64          ┆ ---          │\n",
      "│            ┆            ┆             ┆             ┆              ┆              ┆ f64          │\n",
      "╞════════════╪════════════╪═════════════╪═════════════╪══════════════╪══════════════╪══════════════╡\n",
      "│ count      ┆ 867975     ┆ 867975      ┆ 867975      ┆ 867975.0     ┆ 867975.0     ┆ 867975.0     │\n",
      "│ null_count ┆ 0          ┆ 0           ┆ 0           ┆ 0.0          ┆ 0.0          ┆ 0.0          │\n",
      "│ mean       ┆ null       ┆ null        ┆ null        ┆ 167.592712   ┆ 771.88021    ┆ 5064.732094  │\n",
      "│ std        ┆ null       ┆ null        ┆ null        ┆ 1063.177787  ┆ 4184.228925  ┆ 24025.060173 │\n",
      "│ min        ┆ 01/01/2014 ┆ ANCHIETA    ┆ ANCHIETA    ┆ 1.0          ┆ 1.0          ┆ 10.0         │\n",
      "│ 25%        ┆ null       ┆ null        ┆ null        ┆ 4.0          ┆ 23.0         ┆ 193.0        │\n",
      "│ 50%        ┆ null       ┆ null        ┆ null        ┆ 22.0         ┆ 106.0        ┆ 858.0        │\n",
      "│ 75%        ┆ null       ┆ null        ┆ null        ┆ 81.0         ┆ 411.0        ┆ 3029.0       │\n",
      "│ max        ┆ 31/12/2014 ┆ VILA ISABEL ┆ VILA ISABEL ┆ 44612.0      ┆ 150287.0     ┆ 774785.0     │\n",
      "└────────────┴────────────┴─────────────┴─────────────┴──────────────┴──────────────┴──────────────┘\n",
      "\n",
      "Análise descritiva (.parquet):\n",
      "shape: (9, 7)\n",
      "┌────────────┬────────────┬─────────────┬─────────────┬──────────────┬──────────────┬──────────────┐\n",
      "│ statistic  ┆ day        ┆ origin      ┆ destination ┆ travel_count ┆ travel_count ┆ travell_coun │\n",
      "│ ---        ┆ ---        ┆ ---         ┆ ---         ┆ _no_factor   ┆ _fix_factor  ┆ t_adap_facto │\n",
      "│ str        ┆ str        ┆ str         ┆ str         ┆ ---          ┆ ---          ┆ r            │\n",
      "│            ┆            ┆             ┆             ┆ f64          ┆ f64          ┆ ---          │\n",
      "│            ┆            ┆             ┆             ┆              ┆              ┆ f64          │\n",
      "╞════════════╪════════════╪═════════════╪═════════════╪══════════════╪══════════════╪══════════════╡\n",
      "│ count      ┆ 867975     ┆ 867975      ┆ 867975      ┆ 867975.0     ┆ 867975.0     ┆ 867975.0     │\n",
      "│ null_count ┆ 0          ┆ 0           ┆ 0           ┆ 0.0          ┆ 0.0          ┆ 0.0          │\n",
      "│ mean       ┆ null       ┆ null        ┆ null        ┆ 167.592712   ┆ 771.88021    ┆ 5064.732094  │\n",
      "│ std        ┆ null       ┆ null        ┆ null        ┆ 1063.177787  ┆ 4184.228925  ┆ 24025.060173 │\n",
      "│ min        ┆ 01/01/2014 ┆ ANCHIETA    ┆ ANCHIETA    ┆ 1.0          ┆ 1.0          ┆ 10.0         │\n",
      "│ 25%        ┆ null       ┆ null        ┆ null        ┆ 4.0          ┆ 23.0         ┆ 193.0        │\n",
      "│ 50%        ┆ null       ┆ null        ┆ null        ┆ 22.0         ┆ 106.0        ┆ 858.0        │\n",
      "│ 75%        ┆ null       ┆ null        ┆ null        ┆ 81.0         ┆ 411.0        ┆ 3029.0       │\n",
      "│ max        ┆ 31/12/2014 ┆ VILA ISABEL ┆ VILA ISABEL ┆ 44612.0      ┆ 150287.0     ┆ 774785.0     │\n",
      "└────────────┴────────────┴─────────────┴─────────────┴──────────────┴──────────────┴──────────────┘\n"
     ]
    }
   ],
   "source": [
    "# Conversão de .tab para Polars (.parquet) e comparação de tempo e espaço com análise descritiva\n",
    "\n",
    "# Instala Polars caso não esteja disponível\n",
    "try:\n",
    "    import polars as pl\n",
    "except ImportError:\n",
    "    import sys, subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"polars>=1.0.0\"])\n",
    "    import polars as pl\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Caminhos de arquivo\n",
    "tab_path = \"/workspaces/Stats-In-Codespace/Aula1/julio/RJMA_ordinary_mobility_given_by_two_calls.tab\"\n",
    "parquet_path = os.path.splitext(tab_path)[0] + \".parquet\"\n",
    "\n",
    "def human_bytes(n: int) -> str:\n",
    "    for unit in [\"B\",\"KB\",\"MB\",\"GB\",\"TB\"]:\n",
    "        if n < 1024:\n",
    "            return f\"{n:.2f} {unit}\"\n",
    "        n /= 1024\n",
    "    return f\"{n:.2f} PB\"\n",
    "\n",
    "# 1) Ler .tab com Polars e análise descritiva (medir tempo e memória)\n",
    "t0 = time.perf_counter()\n",
    "df_tab = pl.read_csv(\n",
    "    tab_path,\n",
    "    separator=\"\\t\",\n",
    "    infer_schema_length=10000,\n",
    "    low_memory=True,\n",
    "    null_values=[\"\", \"NA\", \"NaN\", \"null\", \"NULL\"]\n",
    ")\n",
    "t_read_tab = time.perf_counter() - t0\n",
    "\n",
    "mem_tab = df_tab.estimated_size()  # bytes\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "desc_tab = df_tab.describe()\n",
    "t_desc_tab = time.perf_counter() - t0\n",
    "\n",
    "# 2) Converter para Parquet (formato coluna eficiente) e medir espaço/tempo\n",
    "t0 = time.perf_counter()\n",
    "df_tab.write_parquet(parquet_path, compression=\"zstd\", statistics=True)\n",
    "t_write_parquet = time.perf_counter() - t0\n",
    "\n",
    "size_tab = os.path.getsize(tab_path)\n",
    "size_parquet = os.path.getsize(parquet_path)\n",
    "\n",
    "# 3) Ler Parquet e fazer a mesma análise (medir tempo e memória)\n",
    "t0 = time.perf_counter()\n",
    "df_parquet = pl.read_parquet(parquet_path)\n",
    "t_read_parquet = time.perf_counter() - t0\n",
    "\n",
    "mem_parquet = df_parquet.estimated_size()\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "desc_parquet = df_parquet.describe()\n",
    "t_desc_parquet = time.perf_counter() - t0\n",
    "\n",
    "# 4) Resultados\n",
    "print(\"Resumo de Tamanhos em Disco:\")\n",
    "print(f\"- .tab:      {human_bytes(size_tab)}\")\n",
    "print(f\"- .parquet:  {human_bytes(size_parquet)}\")\n",
    "if size_tab > 0:\n",
    "    print(f\"- Fator de redução: {size_tab/size_parquet:.2f}x (tab/parquet)\")\n",
    "\n",
    "print(\"\\nTempos (segundos):\")\n",
    "print(f\"- Leitura .tab:          {t_read_tab:.4f}s\")\n",
    "print(f\"- Escrita .parquet:      {t_write_parquet:.4f}s\")\n",
    "print(f\"- Leitura .parquet:      {t_read_parquet:.4f}s\")\n",
    "print(f\"- Describe .tab:         {t_desc_tab:.4f}s\")\n",
    "print(f\"- Describe .parquet:     {t_desc_parquet:.4f}s\")\n",
    "\n",
    "print(\"\\nMemória estimada dos DataFrames:\")\n",
    "print(f\"- DF (.tab):      {human_bytes(mem_tab)}\")\n",
    "print(f\"- DF (.parquet):  {human_bytes(mem_parquet)}\")\n",
    "\n",
    "print(\"\\nEsquema (dtypes) detectado:\")\n",
    "print(df_tab.schema)\n",
    "\n",
    "print(\"\\nAnálise descritiva (.tab):\")\n",
    "print(desc_tab)\n",
    "\n",
    "print(\"\\nAnálise descritiva (.parquet):\")\n",
    "print(desc_parquet)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
